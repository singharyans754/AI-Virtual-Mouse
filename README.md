# AI Virtual Mouse Using Hand Gestures

The "AI Virtual Mouse Using Hand Gestures" project is a machine learning-based application that allows users to control their computer mouse using hand gestures. The project uses computer vision techniques to recognize hand gestures and convert them into mouse movements. The application utilizes deep learning models to accurately predict hand movements and provides a user-friendly interface for users to interact with their computer.

The project is designed to work on any computer with a camera, making it easily accessible to anyone interested in exploring the capabilities of computer vision and machine learning. The code for the project is available on a Github repository, making it open-source and available for contributions from the community.

## Dependencies -
Please install all the required dependencies.

openCV - (For image processing and drawing).

mediapipe - (For Hand Tracking).

autopy - (For controlling the mouse movement and click).

numpy.

## Installation
To use this project, follow the steps below:

1. Clone the repository:

```
git clone https://github.com/<USERNAME>/AI-Virtual-Mouse.git
```

2. Install the required dependencies using 'pip':

```
pip install -r requirements.txt
```

3. Run the main script:

```
aivirtualmouseproject.py
```

## How to Use

To use the virtual mouse, make sure your computer has a camera and follow the steps below:

1. Run the main script using the steps above.

2. Place your hand in front of the camera with your palm facing down.

3. Make a fist to activate the virtual mouse.

4. Move your fingure to move the mouse pointer.

5. Release your fist to click.

6. Touch thumb and for fingure to right-click.

7. Touch middle fingure and for fingure to left-click.

To exit the application, stop the code running using code editor or directle close the GUI window.

## Contributing

Contributions are welcome! Please feel free to submit a pull request or open an issue if you encounter any bugs or have any suggestions for improvement.
